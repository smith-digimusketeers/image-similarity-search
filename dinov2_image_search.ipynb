{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DINOv2 â€” Imageâ†’Image Similarity Search (Complete Notebook)\n",
        "Swap CLIP for DINOv2 (selfâ€‘supervised ViT) to do image â†’ image semantic similarity. No text needed.\n",
        "\n",
        "âœ… Works on CPU or GPU â€¢ Optional FAISS for speed â€¢ Supports multiple DINOv2 sizes via timm.\n",
        "\n"
      ],
      "metadata": {
        "id": "SH78tWqZ-HxB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Install\n"
      ],
      "metadata": {
        "id": "dWnkZCZj-SNu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HclqbD4Q93MN"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision timm pillow numpy tqdm matplotlib\n",
        "# Optional for large libraries:\n",
        "!pip install faiss-cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLq04hap-ZZm",
        "outputId": "b11658a2-41df-486e-e11e-fa4a3415f794"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Imports & Config\n"
      ],
      "metadata": {
        "id": "e-gtIXEV-UAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "from pathlib import Path\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple, Iterable, Optional, Union\n",
        "\n",
        "import os, json, math, time, dataclasses\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import timm\n",
        "from timm.data import resolve_data_config\n",
        "from timm.data.transforms_factory import create_transform\n",
        "\n",
        "try:\n",
        "    import faiss  # optional\n",
        "    HAS_FAISS = True\n",
        "except Exception:\n",
        "    HAS_FAISS = False\n",
        "\n",
        "# Paths\n",
        "PHOTOS_DIR = Path(\"/content/drive/MyDrive/digi/digi_image-similarity/Photos\") # ðŸ‘ˆ replace\n",
        "INDEX_DIR  = Path('./index_dinov2')\n",
        "INDEX_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Choose a DINOv2 backbone (timm names)\n",
        "# 'vit_small_patch14_dinov2.lvd142m'  (dimâ‰ˆ384)\n",
        "# 'vit_base_patch14_dinov2.lvd142m'   (dimâ‰ˆ768)\n",
        "# 'vit_large_patch14_dinov2.lvd142m'  (dimâ‰ˆ1024)\n",
        "# 'vit_giant_patch14_dinov2.lvd142m'  (dimâ‰ˆ1536)\n",
        "DINO_MODEL = 'vit_base_patch14_dinov2.lvd142m'\n",
        "BATCH_SIZE = 32  # reduce if you hit CUDA OOM\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
      ],
      "metadata": {
        "id": "KC2GI8e5-NFI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Utilities\n"
      ],
      "metadata": {
        "id": "1QwizUjz-iBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_EXTS = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.webp', '.tif', '.tiff'}\n",
        "\n",
        "def list_images(root: Path) -> List[Path]:\n",
        "    files = []\n",
        "    for p in root.rglob('*'):\n",
        "        if p.is_file() and p.suffix.lower() in IMG_EXTS:\n",
        "            files.append(p)\n",
        "    files.sort(); return files\n",
        "\n",
        "\n",
        "def open_image(path: Path) -> Image.Image:\n",
        "    with Image.open(path) as im:\n",
        "        im = ImageOps.exif_transpose(im)\n",
        "        return im.convert('RGB')\n",
        "\n",
        "\n",
        "def chunked(it: Iterable, size: int):\n",
        "    buf = []\n",
        "    for x in it:\n",
        "        buf.append(x)\n",
        "        if len(buf) == size:\n",
        "            yield buf; buf = []\n",
        "    if buf:\n",
        "        yield buf\n",
        "\n",
        "\n",
        "def normalize(a: np.ndarray) -> np.ndarray:\n",
        "    norms = np.linalg.norm(a, axis=1, keepdims=True) + 1e-12\n",
        "    return a / norms\n"
      ],
      "metadata": {
        "id": "jDVBkuUN-hOc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) DINOv2 Encoder (via timm)\n"
      ],
      "metadata": {
        "id": "8sDiu5a3-pu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DinoEncoder:\n",
        "    def __init__(self, model_name: str = DINO_MODEL, device: Optional[str] = None):\n",
        "        self.device = device or DEVICE\n",
        "        self.model = timm.create_model(model_name, pretrained=True).to(self.device)\n",
        "        self.model.eval()\n",
        "        self.dim = getattr(self.model, 'num_features', None) or 768\n",
        "        cfg = resolve_data_config({}, model=self.model)\n",
        "        # Build eval transform matching model's expected mean/std/size\n",
        "        self.transform = create_transform(**cfg, is_training=False)\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def encode_images(self, pil_images: List[Image.Image]) -> np.ndarray:\n",
        "        if not pil_images:\n",
        "            return np.zeros((0, self.dim), dtype=np.float32)\n",
        "        xs = [self.transform(im).unsqueeze(0) for im in pil_images]\n",
        "        x = torch.cat(xs, 0).to(self.device)\n",
        "        feats = self.model.forward_features(x)\n",
        "        # Try to grab preâ€‘logits features robustly\n",
        "        try:\n",
        "            feats = self.model.forward_head(feats, pre_logits=True)\n",
        "        except Exception:\n",
        "            # Fallbacks for various timm return types\n",
        "            if isinstance(feats, dict):\n",
        "                feats = feats.get('x_norm_clstoken', None) or feats.get('avgpool', None) or next(iter(feats.values()))\n",
        "            # If spatial, global average pool\n",
        "            if feats.ndim > 2:\n",
        "                feats = feats.mean(dim=(2,3))\n",
        "        feats = F.normalize(feats, p=2, dim=-1)\n",
        "        return feats.detach().cpu().to(torch.float32).numpy()\n",
        "\n",
        "enc = DinoEncoder(DINO_MODEL)\n",
        "print('Using', DINO_MODEL, 'on', enc.device, '| dim =', enc.dim)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "MCEG3gLa-jv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Onâ€‘Disk Index\n"
      ],
      "metadata": {
        "id": "0-ylr_9n-tgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class ImageMeta:\n",
        "    path: str\n",
        "    mtime: float\n",
        "\n",
        "class DiskIndex:\n",
        "    def __init__(self, index_dir: Path):\n",
        "        self.index_dir = index_dir\n",
        "        self.emb_path = index_dir / 'embeddings.npy'\n",
        "        self.meta_path = index_dir / 'images.jsonl'\n",
        "        self.header_path = index_dir / 'header.json'\n",
        "        self.faiss_path = index_dir / 'faiss.index'\n",
        "\n",
        "    def save(self, header: dict, embeddings: np.ndarray, metas: List[ImageMeta], faiss_index=None):\n",
        "        self.index_dir.mkdir(parents=True, exist_ok=True)\n",
        "        embeddings = normalize(embeddings.astype(np.float32, copy=False))\n",
        "        np.save(self.emb_path, embeddings)\n",
        "        with open(self.meta_path, 'w', encoding='utf-8') as f:\n",
        "            for m in metas:\n",
        "                f.write(json.dumps(dataclasses.asdict(m), ensure_ascii=False) + '\\n')\n",
        "        with open(self.header_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(header, f, ensure_ascii=False, indent=2)\n",
        "        if faiss_index is not None:\n",
        "            faiss.write_index(faiss_index, str(self.faiss_path))\n",
        "\n",
        "    def load(self):\n",
        "        header = json.loads(self.header_path.read_text('utf-8'))\n",
        "        embs = np.load(self.emb_path)\n",
        "        metas = [json.loads(line) for line in self.meta_path.read_text('utf-8').splitlines()]\n",
        "        return header, embs, metas\n",
        "\n",
        "    def try_load_faiss(self):\n",
        "        if HAS_FAISS and self.faiss_path.exists():\n",
        "            return faiss.read_index(str(self.faiss_path))\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "sceiW8rj-sa6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) Build the Index (embed your photo folder)\n"
      ],
      "metadata": {
        "id": "VpO8r5RR-0DJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files = list_images(PHOTOS_DIR)\n",
        "print(f'Found {len(files)} images under {PHOTOS_DIR}')\n",
        "\n",
        "metas: List[ImageMeta] = []\n",
        "all_feats: List[np.ndarray] = []\n",
        "\n",
        "for batch_paths in tqdm(list(chunked(files, BATCH_SIZE)), desc='Embedding', unit='batch'):\n",
        "    pil_batch, batch_metas = [], []\n",
        "    for p in batch_paths:\n",
        "        try:\n",
        "            pil_batch.append(open_image(p))\n",
        "            batch_metas.append(ImageMeta(path=str(p), mtime=p.stat().st_mtime))\n",
        "        except Exception as e:\n",
        "            print('[skip]', p, e)\n",
        "    if not pil_batch: continue\n",
        "    feats = enc.encode_images(pil_batch)\n",
        "    all_feats.append(feats)\n",
        "    metas.extend(batch_metas)\n",
        "\n",
        "if not metas:\n",
        "    raise SystemExit('No images embedded â€” check PHOTOS_DIR')\n",
        "\n",
        "embeddings = np.vstack(all_feats)\n",
        "header = {\n",
        "    'backbone': DINO_MODEL,\n",
        "    'dim': int(embeddings.shape[-1]),\n",
        "    'created_at': time.time(),\n",
        "    'num_items': len(metas),\n",
        "    'device_build': enc.device,\n",
        "}\n",
        "\n",
        "index = DiskIndex(INDEX_DIR)\n",
        "index.save(header, embeddings, metas)\n",
        "print(f'Saved DINOv2 index â†’ {INDEX_DIR} with {len(metas)} items.')\n"
      ],
      "metadata": {
        "id": "RssE_ZN1-zCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7) Image â†’ Image Search (cosine or FAISS IP)\n"
      ],
      "metadata": {
        "id": "0TCg3skJ-4HQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Union\n",
        "\n",
        "@torch.inference_mode()\n",
        "def encode_query_image(img: Union[str, Path, Image.Image]) -> np.ndarray:\n",
        "    if isinstance(img, (str, Path)):\n",
        "        pil = open_image(Path(img))\n",
        "    else:\n",
        "        pil = img\n",
        "    return enc.encode_images([pil])[0].astype(np.float32)\n",
        "\n",
        "\n",
        "def search_image(index_dir: Path, query_image: Union[str, Path, Image.Image], topk: int = 12,\n",
        "                 prefer_faiss: bool = True, include_self: bool = False):\n",
        "    index = DiskIndex(index_dir)\n",
        "    header, embs, metas = index.load()\n",
        "    embs = normalize(embs.astype(np.float32))\n",
        "\n",
        "    q = encode_query_image(query_image)  # (D,)\n",
        "\n",
        "    if prefer_faiss and HAS_FAISS:\n",
        "        fidx = index.try_load_faiss()\n",
        "        if fidx is None:\n",
        "            fidx = faiss.IndexFlatIP(header['dim'])\n",
        "            fidx.add(embs)\n",
        "        D, I = fidx.search(q[None, :], min(topk+10, len(embs)))\n",
        "        candidates = [(metas[int(i)], float(d)) for i, d in zip(I[0], D[0]) if int(i) >= 0]\n",
        "    else:\n",
        "        sims = embs @ q\n",
        "        idx = np.argsort(-sims)[:topk+10]\n",
        "        candidates = [(metas[int(i)], float(sims[int(i)])) for i in idx]\n",
        "\n",
        "    q_path = None\n",
        "    if isinstance(query_image, (str, Path)):\n",
        "        q_path = str(Path(query_image).resolve())\n",
        "    results = []\n",
        "    for meta, score in candidates:\n",
        "        p = str(Path(meta['path']).resolve())\n",
        "        if not include_self and q_path is not None and p == q_path:\n",
        "            continue\n",
        "        results.append((meta, score))\n",
        "        if len(results) >= topk:\n",
        "            break\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "e1TS5zUj-1zl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8) Visualization\n"
      ],
      "metadata": {
        "id": "QlCIXujt_aMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_query_and_results(query_image: Union[str, Path, Image.Image], results: List[Tuple[dict, float]],\n",
        "                           cols: int = 4, max_w: int = 320, title: str = None):\n",
        "    if isinstance(query_image, (str, Path)):\n",
        "        q_img = open_image(Path(query_image)); q_title = Path(query_image).name\n",
        "    else:\n",
        "        q_img = query_image; q_title = 'query'\n",
        "\n",
        "    plt.figure(figsize=(4,4))\n",
        "    plt.imshow(q_img); plt.axis('off')\n",
        "    plt.title(f\"Query: {q_title}\")\n",
        "    plt.show()\n",
        "\n",
        "    if not results:\n",
        "        print('No neighbors.'); return\n",
        "    rows = math.ceil(len(results)/cols)\n",
        "    if title: print(title)\n",
        "    plt.figure(figsize=(cols*4, rows*4))\n",
        "    for i, (meta, score) in enumerate(results, start=1):\n",
        "        try:\n",
        "            img = open_image(Path(meta['path']))\n",
        "            img.thumbnail((max_w, max_w))\n",
        "            plt.subplot(rows, cols, i)\n",
        "            plt.imshow(img)\n",
        "            plt.axis('off')\n",
        "            plt.title(f\"{score:.3f}\\n{Path(meta['path']).name}\", fontsize=9)\n",
        "        except Exception as e:\n",
        "            print('[viz-skip]', meta['path'], e)\n",
        "    plt.tight_layout(); plt.show()\n"
      ],
      "metadata": {
        "id": "pvI9eJsJ_ZYL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_image_path = \"/content/Gemini_Generated_Image_4qdc6c4qdc6c4qdc.png\"  # ðŸ‘ˆ set a specific file if you like\n",
        "neighbors = search_image(INDEX_DIR, query_image_path, topk=12, prefer_faiss=True, include_self=False)\n",
        "show_query_and_results(query_image_path, neighbors, cols=4, title='DINOv2 â€” Imageâ†’Image')\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "0St3fUBi_cU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AgLhwrwh_dym"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}